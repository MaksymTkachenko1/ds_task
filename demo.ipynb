{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modified-title",
   "metadata": {},
   "source": [
    "# Task 1: MNIST + OOP\n",
    "\n",
    "This notebook demonstrates an object‚Äêoriented approach for MNIST classification using three models:\n",
    "1. Random Forest\n",
    "2. Feed-Forward Neural Network\n",
    "3. Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb917a8a",
   "metadata": {},
   "source": [
    "I'm choosing to use a Jupyter notebook because Docker and VS Code environments have caused persistent dependency and configuration issues, leading to long build times and debugging headaches. Given the one-week deadline, Jupyter offers a ready-to-use, minimal-overhead environment that lets me focus on coding and quickly iterate without the extra complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ce559",
   "metadata": {},
   "source": [
    "## 1. Task 1: MNIST + OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6a82ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maksy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf8148",
   "metadata": {},
   "source": [
    "### 1.1. Define the Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dccc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifierInterface(ABC):\n",
    "    \"\"\"\n",
    "    Interface requiring two abstract methods:\n",
    "     - train(train_data, train_targets)\n",
    "     - predict(test_data)\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def train(self, train_data, train_targets):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, test_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e96f58",
   "metadata": {},
   "source": [
    "### 1.2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2a4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfMnistClassifier(MnistClassifierInterface):\n",
    "    def __init__(self, n_estimators=100):\n",
    "        self.model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "    def train(self, train_data, train_targets):\n",
    "        self.model.fit(train_data, train_targets)\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        return self.model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e44bbb",
   "metadata": {},
   "source": [
    "### 1.3. Feed-Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54be868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardMnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class NnMnistClassifier(MnistClassifierInterface):\n",
    "    def __init__(self, epochs=5, lr=1e-3, batch_size=64):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.model = FeedForwardMnist()\n",
    "\n",
    "    def train(self, train_data, train_targets):\n",
    "        X = torch.from_numpy(train_data).float()\n",
    "        y = torch.from_numpy(train_targets).long()\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.model.train()\n",
    "        for _ in range(self.epochs):\n",
    "            for batch_x, batch_y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                out = self.model(batch_x)\n",
    "                loss = criterion(out, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        X = torch.from_numpy(test_data).float()\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.model(X)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "        return preds.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bfdb2",
   "metadata": {},
   "source": [
    "### 1.4. CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313a7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvMnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*7*7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "class CnnMnistClassifier(MnistClassifierInterface):\n",
    "    def __init__(self, epochs=5, lr=1e-3, batch_size=64):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.model = ConvMnistNet()\n",
    "        \n",
    "    def train(self, train_data, train_targets):\n",
    "        X = torch.from_numpy(train_data).float().view(-1,1,28,28)\n",
    "        y = torch.from_numpy(train_targets).long()\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.model.train()\n",
    "        for _ in range(self.epochs):\n",
    "            for batch_x, batch_y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                out = self.model(batch_x)\n",
    "                loss = criterion(out, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        X = torch.from_numpy(test_data).float().view(-1,1,28,28)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.model(X)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "        return preds.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a262efc",
   "metadata": {},
   "source": [
    "### 1.5. Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa4befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifier:\n",
    "    def __init__(self, algorithm='rf'):\n",
    "        if algorithm == 'rf':\n",
    "            self.impl = RfMnistClassifier()\n",
    "        elif algorithm == 'nn':\n",
    "            self.impl = NnMnistClassifier()\n",
    "        elif algorithm == 'cnn':\n",
    "            self.impl = CnnMnistClassifier()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported algorithm: {algorithm}\")\n",
    "\n",
    "    def train(self, train_data, train_targets):\n",
    "        self.impl.train(train_data, train_targets)\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        return self.impl.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a280dc2a",
   "metadata": {},
   "source": [
    "### 1.6. Demo on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad6ca31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9443\n",
      "Feed-Forward NN Accuracy: 0.9261\n",
      "CNN Accuracy: 0.9628\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST and do a small training demo\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST(root='./mnist_data', train=True, download=True, transform=mnist_transform)\n",
    "test_mnist = torchvision.datasets.MNIST(root='./mnist_data', train=False, download=True, transform=mnist_transform)\n",
    "\n",
    "# We'll just take 5k from the training set to keep it quick\n",
    "train_small, _ = random_split(train_mnist, [5000, len(train_mnist)-5000])\n",
    "\n",
    "def dataset_to_numpy(dataset):\n",
    "    images, labels = [], []\n",
    "    for img, label in dataset:\n",
    "        # Convert to numpy array\n",
    "        np_img = np.array(img).astype(np.float32)\n",
    "        images.append(np_img)\n",
    "        labels.append(label)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "# Convert\n",
    "X_train_mnist, y_train_mnist = dataset_to_numpy(train_small)\n",
    "X_test_mnist, y_test_mnist = dataset_to_numpy(test_mnist)\n",
    "\n",
    "# Flatten for rf/nn\n",
    "X_train_flat = X_train_mnist.reshape(-1, 28*28)\n",
    "X_test_flat = X_test_mnist.reshape(-1, 28*28)\n",
    "\n",
    "# 1) Random Forest\n",
    "rf_model = MnistClassifier(algorithm='rf')\n",
    "rf_model.train(X_train_flat, y_train_mnist)\n",
    "rf_preds = rf_model.predict(X_test_flat)\n",
    "rf_acc = accuracy_score(y_test_mnist, rf_preds)\n",
    "print(\"Random Forest Accuracy:\", rf_acc)\n",
    "\n",
    "# 2) Feed-forward NN\n",
    "nn_model = MnistClassifier(algorithm='nn')\n",
    "nn_model.train(X_train_flat, y_train_mnist)\n",
    "nn_preds = nn_model.predict(X_test_flat)\n",
    "nn_acc = accuracy_score(y_test_mnist, nn_preds)\n",
    "print(\"Feed-Forward NN Accuracy:\", nn_acc)\n",
    "\n",
    "# 3) CNN\n",
    "cnn_model = MnistClassifier(algorithm='cnn')\n",
    "cnn_model.train(X_train_flat, y_train_mnist)\n",
    "cnn_preds = cnn_model.predict(X_test_flat)\n",
    "cnn_acc = accuracy_score(y_test_mnist, cnn_preds)\n",
    "print(\"CNN Accuracy:\", cnn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We've shown an object-oriented approach for MNIST classification using three models (Random Forest, Feed-Forward NN, and CNN)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
